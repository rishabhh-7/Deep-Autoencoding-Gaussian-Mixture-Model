{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e86ff4d",
   "metadata": {},
   "source": [
    "anomaly_dataset/normal/      # Only forest images\n",
    "\n",
    "anomaly_dataset/anomaly/     # All other categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca67180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e206d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da99cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base directory of the dataset\n",
    "base_dir = \"archive/seg_test/seg_test\"\n",
    "# Define classes\n",
    "normal_class = \"forest\"\n",
    "anomaly_classes = [\"buildings\", \"glacier\", \"mountain\", \"sea\", \"street\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33383cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete:\n",
      "  Train → normal=284, anomaly=0\n",
      "   Val  → normal=95, anomaly=20\n",
      "   Test → normal=95, anomaly=20\n"
     ]
    }
   ],
   "source": [
    "# 1) Paths & classes\n",
    "base_dir        = Path(\"archive/seg_test/seg_test\")\n",
    "normal_class    = \"forest\"\n",
    "anomaly_classes = [\"buildings\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "output_dir      = Path(\"split_anomaly_dataset\")\n",
    "\n",
    "# 2) Helper to copy files into a folder\n",
    "def make_split(file_list, target_dir):\n",
    "    target_dir = Path(target_dir)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in file_list:\n",
    "        shutil.copy(f, target_dir / f.name)\n",
    "\n",
    "# 3) Gather all file paths\n",
    "normal_files   = list((base_dir / normal_class).glob(\"*.jpg\"))\n",
    "anomaly_files  = []\n",
    "for cls in anomaly_classes:\n",
    "    anomaly_files += list((base_dir / cls).glob(\"*.jpg\"))\n",
    "\n",
    "# 4) Split normals: 60% train, 20% val, 20% test\n",
    "n_train = int(len(normal_files) * 0.6)\n",
    "train_norm, temp_norm = train_test_split(normal_files, train_size=n_train, random_state=42)\n",
    "val_norm, test_norm   = train_test_split(temp_norm, test_size=0.5,     random_state=42)\n",
    "\n",
    "# 5) Split anomalies: 50% val, 50% test (no anomalies in train)\n",
    "val_anom, test_anom = train_test_split(anomaly_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# ↓ only take *up to* N anomalies in each split ↓\n",
    "MAX_ANOM_VAL  = 20\n",
    "MAX_ANOM_TEST = 20\n",
    "\n",
    "val_anom  = random.sample(val_anom,  min(len(val_anom),  MAX_ANOM_VAL))\n",
    "test_anom = random.sample(test_anom, min(len(test_anom), MAX_ANOM_TEST))\n",
    "\n",
    "# 6) Copy into folder structure (unchanged)\n",
    "for split, normals, anoms in [\n",
    "    (\"train\", train_norm, []),\n",
    "    (\"val\",   val_norm,   val_anom),\n",
    "    (\"test\",  test_norm,  test_anom),\n",
    "]:\n",
    "    make_split(normals, output_dir / split / \"normal\")\n",
    "    make_split(anoms,    output_dir / split / \"anomaly\")\n",
    "\n",
    "print(\"Dataset split complete:\")\n",
    "print(f\"  Train → normal={len(train_norm)}, anomaly=0\")\n",
    "print(f\"   Val  → normal={len(val_norm)}, anomaly={len(val_anom)}\")\n",
    "print(f\"   Test → normal={len(test_norm)}, anomaly={len(test_anom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83d9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly dataset created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Define classes\n",
    "normal_class = \"forest\"\n",
    "anomaly_classes = [\"buildings\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "\n",
    "# Output directories\n",
    "output_dir = \"anomaly_dataset\"\n",
    "normal_dir = os.path.join(output_dir, \"normal\")\n",
    "anomaly_dir = os.path.join(output_dir, \"anomaly\")\n",
    "\n",
    "# Create output folders\n",
    "os.makedirs(normal_dir, exist_ok=True)\n",
    "os.makedirs(anomaly_dir, exist_ok=True)\n",
    "\n",
    "# Copy normal class images\n",
    "for img_name in os.listdir(os.path.join(base_dir, normal_class)):\n",
    "    src = os.path.join(base_dir, normal_class, img_name)\n",
    "    dst = os.path.join(normal_dir, img_name)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Copy anomaly class images\n",
    "for cls in anomaly_classes:\n",
    "    class_path = os.path.join(base_dir, cls)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        src = os.path.join(class_path, img_name)\n",
    "        dst = os.path.join(anomaly_dir, f\"{cls}_{img_name}\")\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"Anomaly dataset created!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
